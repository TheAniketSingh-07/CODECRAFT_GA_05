# CODECRAFT_GA_05

# ğŸ¨ Neural Style Transfer using TensorFlow 

> *"Combining the soul of one image with the structure of another â€” thatâ€™s the power of Generative AI."*

## ğŸ“Œ Internship Task Overview

As part of my **Generative AI Internship at CodeCraft**, I was assigned a core project: **Neural Style Transfer (NST)**. The goal was to build a Python-based system that takes a **content image** (structure) and a **style image** (artistic texture) and blends them into a **stylized image**, using **deep learning** techniques.

This project focuses on applying a pre-trained deep learning model (**VGG19**) to merge two visual inputs and generate artistic outputs through **gradient-based optimization**.

---

## ğŸ–¼ï¸ Sample Result

<p align="center">
  <img src="example.png" width="100%"/> 
</p>

---

## ğŸ§  What I Learned

- How **pre-trained convolutional neural networks** (CNNs) extract feature maps.
- How to optimize image pixels using **loss functions** instead of updating model weights.
- Learned concepts like:
  - **Content loss**, **Style loss**, and **Total variation loss**
  - Using **TensorFlow GradientTape**
  - Real-time image generation using **interactive sliders** in Colab.
- Best practices for **Colab deployment**, image preprocessing, and result visualization.

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/neural-style-transfer.git
   cd neural-style-transfer
Install Dependencies

pip install -q tensorflow matplotlib


ğŸ§° Tools & Technologies Used
ğŸ§  TensorFlow â€“ For neural network processing and optimization

ğŸ¨ VGG19 â€“ Pre-trained model for feature extraction

ğŸ“Š Matplotlib â€“ Image display and plotting

ğŸ“ IPyWidgets â€“ For slider interaction in Colab

ğŸ” Google Colab â€“ Fast prototyping environment

ğŸ’¾ Pillow (PIL) â€“ Image processing

ğŸ§‘â€ğŸ’» Core Code Explanation
Here's a simplified version of the main logic:


# Load the content and style image
content_image = load_img("content.jpg")
style_image = load_img("style.jpg")

# Preprocess and extract features
model = VGG19(include_top=False, weights='imagenet')
outputs = model([content_image, style_image])

# Define loss functions
content_loss = MSE(content_features, generated_features)
style_loss = GramMatrixLoss(style_features, generated_features)

# Minimize total loss
optimizer = tf.optimizers.Adam(learning_rate=5.0)
train_step = optimizer.minimize(total_loss, var_list=[generated_image])
âœ… Full code is available in the notebook with comments and visualization at each stage.

ğŸ› ï¸ How I Solved the Problems
âœ… Fixed upload errors by reordering cells for extractor and file handling.

âœ… Solved structure mismatch warnings in TensorFlow by standardizing shapes.

âœ… Fixed runtime freeze by reducing iterations and switching to CPU optimization-friendly format.

âœ… Used tight layout and axis hiding for clean visual output.

âœ… Added files.download() to download generated image after result.

ğŸ“¥ Output Features
Upload content and style images interactively

See all three images (content, style, and result) side-by-side

Adjustable iterations (50â€“500 range) using slider

One-click download button for stylized output

ğŸŒŸ Future Improvements
Integrate GAN-based transfer models (like Fast Style Transfer).

Add batch processing for generating multiple results.

Improve quality with adaptive learning rate scheduling.

âœ¨ Final Thoughts
This project was more than just coding â€“ it was an artistic exploration powered by deep learning. I now understand how AI can create expressive visual experiences.

Big thanks to CodeCraft for the incredible opportunity to explore Generative AI in a hands-on way.
Author - Aniket Singh

ğŸ¤ Connect with Me
ğŸ“§ aniket@example.com
ğŸ”— LinkedIn
ğŸ§  Portfolio


